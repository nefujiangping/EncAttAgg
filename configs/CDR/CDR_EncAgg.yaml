# data for train/test
data_path: "./data/CDR"
bert_embedding_dir: "./data/CDR"
checkpoint_dir: "./checkpoint"
log_dir: "./log"
summary_dir: "./summary"

dataset: "CDR"
train_prefix: "dev_train"  # train+dev
test_prefix: "dev_test"

# embedding
max_length: 620 # max length of CDR is 620
use_bert_embedding: false
bert_embedd_dim: 768
# if use_bert_embedding=true and embedd_dim < bert_embedd_dim,
#  bert embedding will be down-project to bert_embedd_dim
embedd_dim: 200
# For `use_bert_embedding`=false, whether to freeze the embedding matrix
freeze_embedd: false # tune the PubMed embedding when training
drop_word:
  use_drop: true  # For CDR we use dropout on word embedding, because of fewer relation types
  drop: 0.5  # ratio of drop word
entity_type_size: 20
entity_type_num: 3  # 2 entity types (Chemical, Disease) plus `NONE`
coref_size: 20
dis_size: 20

# encoder
nlayer: 1  # number of BiLSTM layer
cat_nlayer: false  # Whether cat output of BiLSTM layers
lstm_keep_prob: 0.8
hidden_size: 128

# attenders
entity_span_pooling: "mean"  #
coref_pooling: "mean"  # This is useless for EndAttAgg model
which_model: "EncAttAgg"  # EncAgg, BiLSTM, BRAN-M
mutual_attender:
  attender: "NONE"  # ML-MMA(MultiLayer Mutual Multi-Head Attention), NONE
  num_layers: 1
  nhead: 8
  shared: true
  drop: 0.1
integration_attender:
  attender: "NONE"  # ML-MA(MultiLayer Multi-Head Attention), NONE
  num_layers: 1
  nhead: 8
  drop: 0.1
use_distance: true
use_overlap: true
use_bilinear: false  # This is useless for EndAttAgg model which always use `Linear` as final scorer
relation_num: 2  # For CDR, 1 relation type (Chemical-Induced Disease) plus `NONE`
train_on_trainanddev: true  # merge train/dev sets to train model
lowercase: true  # whether lowercase tokens

# other hyper-parameters
batch_size: 16
init_lr: 3.0e-4  # 3e-4
use_lr_scheduler: false
train_rel_limit_per_example: 506  # use all positive/negative pairs, to train
train_hypernym_filter: true  # perform hypernym filtering to remove some negative pairs
max_epoch: 25
epoch_start_to_eval: 0
# For test
test_batch_size: 1  # aggregating all mention pairs is memory-consuming, so we set a small test batch size here
test_rel_limit_per_example: 506  # all possible pairs should be fed for prediction
test_hypernym_filter: true  # perform hypernym filtering to remove some negative pairs
# average the parameters over the recent epochs, to to make the test performance be stable
avg_params:
  use_avg_params: true
  num_recent_epochs: 10  # `0` means averaging the parameters up to this epoch





